{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"AutoMAxO","text":"<p>Welcome to AutoMAxO! </p>"},{"location":"#a-brief-intro","title":"A Brief Intro","text":"<p>AutoMAxO leverages the power of Large Language Models (LLMs) to streamline the biocuration of medical actions for rare diseases. By automating the annotation process of clinical management data, AutoMAxO significantly enhances efficiency and scalability, making it easier for researchers and healthcare professionals to access and utilize critical information.</p>"},{"location":"#setup","title":"Setup","text":"<p>To get started with AutoMAxO, please refer to our installation instructions. This guide will walk you through the steps required to install and configure AutoMAxO on your system.</p>"},{"location":"#tutorial","title":"Tutorial","text":"<p>After setting up the proper environment, you can run AutoMAxO by executing the following command:</p> <pre><code>python main.py\n</code></pre> <p>You will then be prompted to enter a disease name and the maximum number of articles you would like to process.</p> <p>The final file will be saved as .json file. under this path: <pre><code>data/disease_name/final_automaxo_results.json\n</code></pre></p> <p>To gain a deeper understanding of how to use AutoMAxO and explore its full potential for various applications, check out our comprehensive Tutorial. This tutorial provides detailed instructions and an example to help you navigate and maximize the capabilities of the AutoMAxO pipeline.</p>"},{"location":"install/","title":"Installation","text":""},{"location":"install/#1-prerequisites","title":"1. Prerequisites","text":"<p>Ensure you have the following installed: * Python: &gt;=3.9, &lt;3.9.7 or &gt;3.9.7, &lt;3.11 * Poetry * OpenAI API Key</p>"},{"location":"install/#install-the-right-version-of-python","title":"Install the Right Version of Python","text":"<p>AutoMAxO requires Python 3.9. There are many ways to set this up, and users should consult documentation specific to their system.</p>"},{"location":"install/#install-poetry","title":"Install Poetry","text":"<p>AutoMAxO is set up using the dependency manager Poetry.</p> <p>Once you have Python 3.9 installed, it may be necessary to specify the Python version to Poetry. For instance, on our system, both Python 3.12 and 3.9 are installed, and Python 3.9 is available at <code>/usr/bin</code>.</p> <p>Therefore, we run this command:</p> <pre><code>poetry env use /usr/bin/python3\n</code></pre>"},{"location":"install/#2-setting-up-the-project","title":"2. Setting Up the Project","text":"<p>Clone the AutoMAxO repository and navigate to the project directory:</p> <pre><code>git clone https://github.com/monarch-initiative/automaxo\ncd automaxo\n</code></pre>"},{"location":"install/#3-installation-of-automaxo-environment","title":"3. Installation of AutoMAxO Environment","text":"<p>After Poetry is using Python 3.9, you can install the tool by navigating to the <code>automaxo</code> directory and executing the following commands. Note that the first command will take several minutes.</p> <pre><code>poetry install\npoetry shell\n</code></pre> <p>or use this in case the above activation does not work  try use this:</p> <pre><code>poetry install\nsource $(poetry env info --path)/bin/activate\n</code></pre> <p>Add your OpenAI key:</p> <pre><code>runoak set-apikey -e openai &lt;your_openai_api_key&gt;\n</code></pre>"},{"location":"install/#4-running-the-script","title":"4. Running the Script","text":"<p>You can run the script using the following command:</p> <pre><code>python main.py\n</code></pre> <p>You will then be prompted to enter a disease name and the number of articles to be processed.</p> <p>Alternatively, you can run this command all at once:</p> <pre><code>python main.py --disease_name \"YourDiseaseName\" --max_articles_to_save 100\n</code></pre> <p>Replace \"YourDiseaseName\" with the name of the disease you want to process and adjust <code>100</code> to the desired number of articles to be processed.</p>"},{"location":"tutorial/","title":"AutoMAxO Tutorial","text":"<p>Welcome to the AutoMAxO tutorial. This guide will walk you through running the AutoMAxO project step by step.</p>"},{"location":"tutorial/#note","title":"Note:","text":"<p>There are two options to run the whole AutoMAxO pipeline depending on your usage: 1. You can run the entire project with just one command if you would like to retrieve a certain number of articles that discuss therapeutics and extract medical actions.</p> <p><pre><code>python main.py --disease_name \"YourDiseaseName\" --max_articles_to_save 100\n</code></pre> Replace \"YourDiseaseName\" with the name of the disease you want to process and adjust <code>100</code> to the desired number of articles to save.</p> <ol> <li>You can run each file separately to easily modify and integrate AutoMAxO into different applications to accomplish various tasks. In this tutorial, we will be using \"sickle cell\" as a sample disease, but you can change it to any name you prefer. Follow the step-by-step instructions below:</li> </ol>"},{"location":"tutorial/#step-1-extract-mesh-sets-from-target-mesh-ids","title":"Step 1: Extract MeSH Sets from Target MeSH IDs","text":"<p>The script, <code>mesh_importer.py</code>, reads a list of targeted MeSH IDs and their labels to create a formatted file with MeSH sets required for the AutoMAxO project.</p> Option Meaning --input-file Path to the .tsv file containing MeSH target IDs --output-file Path to the output .tsv file with MeSH sets <p>For example:</p> <p><pre><code>python mesh_importer.py --input-file path/to/mesh_target_ids.tsv --output-file path/to/mesh_sets.tsv\n</code></pre> The default format for <code>mesh_target_ids</code> in the project is as follows:</p> mesh.id label D013812 Therapeutics <p>Sample output for <code>mesh_sets</code>:</p> label mesh.id mesh set Therapeutics D013812 061645;D000075162;D000161;D000203;D019050"},{"location":"tutorial/#step-2-retrieve-mesh-ids","title":"Step 2: Retrieve MeSH IDs","text":"<p>The script, <code>pubmed_article_fetcher.py</code>,start by retrieving raw data and MeSH IDs related to the treatment of your specified disease. In this stage, the script first checks whether there are already existing articles in the directory to avoid duplicate extraction. It ensures that the new articles being extracted are not the same as the ones already existing in the directory, and attempts to extract up to the maximum number specified by the user.</p> Option Meaning -d Disease name -m Path to the .tsv file with MeSH sets created in Step 1 -o Directory where retrieved articles will be saved in the form of .json files -j Path to the .json file to save MeSH IDs related to retrieved articles -n Maximum number of articles to retrieve <p>For example:</p> <pre><code>python pubmed_article_fetcher.py -d \"sickle cell\" -m ../../data/mesh_sets.tsv -o ../../data/sickle_cell/pubtator3_json/ -j ../../data/sickle_cell/selected_pmid_mesh_info.json -n 2\n</code></pre> <p>Note: * The disease name is not case-sensitive. * The maximum number of articles will include articles both about a specific disease and having at least one of the MeSH IDs in the MeSH sets from Step 1, meaning articles about therapeutics of a specific disease, for example, in our use case.</p>"},{"location":"tutorial/#step-3-pre-process-extracted-data-from-json-files","title":"Step 3: Pre-process Extracted Data from JSON Files","text":"<p>The script, <code>article_data_extractor.py</code>, extracts data from JSON files and saves the text where each row represents the title and abstract of an article.</p> Option Meaning -i Directory containing JSON files produced in Step 2 -n Path to the .tsv file for pre-processed text data <p>For example:</p> <p><pre><code>python article_data_extractor.py -i ../../data/sickle_cell/pubtator3_json/ -n ../../data/sickle_cell/sickle_cell_no_replaced.tsv\n</code></pre> If you would like to extract annotations from custom texts, including full PubMed Central texts, websites, or other text collections, you need to format your text into a TSV (Tab-Separated Values) file. This file must contain three columns: PMID, Title, and Abstract. The PMID column can be left empty or populated with unique identifiers if available. The format should match the output format required by the processing function.</p> PMID Title Abstract 28669521 Management of delayed hemolytic transfusion reaction ... Transfusion remains a key treatment of sickle cell disease..."},{"location":"tutorial/#step-4-integrate-ontogpt","title":"Step 4: Integrate OntoGPT","text":"<p>The script, <code>ontogpt_article_processor.py</code>, processes the text data from the pre-processed .tsv file using OntoGPT. Each row in the .tsv file is treated as an input text for OntoGPT. For more information about OntoGPT, please refer to this repo. </p> Option Meaning -i Path to the .tsv file for pre-processed text produced in Step 3 -o Directory containing YAML files produced by LLMs (OntoGPT) -template Name of the template for OntoGPT (default = 'maxo') <p>For example:</p> <pre><code>python ontogpt_article_processor.py -i ../../data/sickle_cell/sickle_cell_no_replaced.tsv -o ../../data/sickle_cell/ontoGPT_yaml/\n</code></pre>"},{"location":"tutorial/#step-5-post-process-llm-results","title":"Step 5: Post-process LLM Results","text":"<p>The script, <code>ontology_validation.py</code>,  Post-process LLM results from separate YAML files into a single JSON file. This includes further grounding of terms to the existing ontologies and ranking extracted triplets by frequency of appearance.</p> Option Meaning -i Directory containing YAML files produced in Step 4 -s Path to the .json file to save MeSH IDs related to retrieved articles produced in Step 2 -n Path to the .tsv file for pre-processed text produced in Step 3 -o Path to the .json file to save post-processed LLM results in one file <p>For example:</p> <pre><code>python triplet_ranking_and_mesh_combiner.py -i ../../data/sickle_cell/ontoGPT_yaml/ -s ../../data/sickle_cell/selected_pmid_mesh_info.json -n ../../data/sickle_cell/sickle_cell_no_replaced.tsv -o ../../data/sickle_cell/detailed_post_ontoGPT.json\n</code></pre>"},{"location":"tutorial/#step-6-validate-annotations","title":"Step 6: Validate Annotations","text":"<p>The script, <code>ontology_validation.py</code>, updates ontology labels in a JSON file by validating and augmenting MAXO, HPO, and MONDO IDs with their corresponding labels. It processes the JSON data, generates ontology term files using <code>runoak</code>, and integrates these terms into the JSON file to enhance the dataset with accurate ontology information.</p> Option Meaning -json_file_path Path to the .json file of post-processed LLM results produced in Step 5 -output_file_path Path to the .json file, final result of validated ontologies produced by automaxo <p>For example:</p> <pre><code>python ontology_validation.py ../../data/sickle_cell/detailed_post_ontoGPT.json ../../data/sickle_cell/final_automaxo_results.json\n</code></pre>"},{"location":"tutorial/#running-the-script","title":"Running the Script","text":"<p>You can run the script using the following command:</p> <p><pre><code>python main.py --disease_name \"YourDiseaseName\" --max_articles_to_save 100\n</code></pre> Replace \"YourDiseaseName\" with the name of the disease you want to process and adjust <code>100</code> to the desired number of articles to save.</p>"}]}