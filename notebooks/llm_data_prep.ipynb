{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# Ensure required resources are downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Seed keywords\n",
    "seed_keywords = [\"treatment\", \"diagnosis\", \"therapy\"]\n",
    "\n",
    "# Expand keywords using WordNet\n",
    "expanded_keywords = set(seed_keywords)\n",
    "for keyword in seed_keywords:\n",
    "    for synset in wn.synsets(keyword):\n",
    "        expanded_keywords.update(lemma.name() for lemma in synset.lemmas())\n",
    "\n",
    "# Sample text\n",
    "large_text = \"\"\"\n",
    "Section 1: The patient was diagnosed with diabetes.\n",
    "Section 2: Treatment options include metformin and insulin therapy.\n",
    "Section 3: Regular exercise is recommended.\n",
    "\"\"\"\n",
    "\n",
    "# Segmentation\n",
    "sections = large_text.split(\"\\n\")\n",
    "\n",
    "# Keyword matching and section selection\n",
    "relevant_sections = []\n",
    "for section in sections:\n",
    "    tokens = word_tokenize(section.lower())\n",
    "    if any(keyword in tokens for keyword in expanded_keywords):\n",
    "        relevant_sections.append(section)\n",
    "\n",
    "print(\"Relevant Sections:\", relevant_sections)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
