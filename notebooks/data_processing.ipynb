{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated function based on the provided structure and logic for building new text with replacements\n",
    "def correct_replacements(passages):\n",
    "    biotype_prefix = {\n",
    "        \"gene\": \"ncbi\",\n",
    "        \"disease\": \"disease\",\n",
    "        \"chemical\": \"chemical\",\n",
    "        \"variant\": \"variant\",\n",
    "        \"specie\": \"specie\",\n",
    "        \"cell line\": \"cellosaurus\"\n",
    "    }\n",
    "    \n",
    "    for passage in passages:\n",
    "        new_text = \"\"\n",
    "        last_offset = 0\n",
    "        text_offset = passage[\"offset\"] # Initialize last_offset to the start of the passage text        \n",
    "        for annotation in sorted(passage[\"annotations\"], key=lambda x: x[\"locations\"][0][\"offset\"]):\n",
    "            biotype = annotation[\"infons\"][\"biotype\"]\n",
    "            normalized_id = annotation[\"infons\"][\"normalized_id\"]\n",
    "            if normalized_id:\n",
    "                prefix = biotype_prefix.get(biotype, \"\")\n",
    "                replacement_text = f\"{prefix}{normalized_id}\"\n",
    "                for location in annotation[\"locations\"]:\n",
    "                    start = location[\"offset\"] - text_offset\n",
    "                    end = start + location[\"length\"]\n",
    "                    # Append text from last_offset to the start of the current annotation\n",
    "                    new_text += passage[\"text\"][last_offset:start]\n",
    "                    # Append the replacement text\n",
    "                    new_text += replacement_text\n",
    "                    # Update last_offset to after the current annotation\n",
    "                    last_offset = end\n",
    "        # Append any remaining text after the last annotation\n",
    "        new_text += passage[\"text\"][last_offset:]\n",
    "        # Update the passage text with the new constructed text\n",
    "        passage[\"text\"] = new_text\n",
    "    \n",
    "    return passages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_jsons_to_tsv(json_files_path, replaced_tsv_file_path, no_replaced_tsv_file_path):\n",
    "    \"\"\"\n",
    "    Processes JSON files in the given directory, extracting PMC ID and text content,\n",
    "    and saves them into a single TSV file with two columns: PMC ID and text.\n",
    "\n",
    "    Parameters:\n",
    "    - json_files_path (str): The path to the directory containing JSON files.\n",
    "    - replaced_tsv_file_path (str): The path to the output TSV file where replacement occured .\n",
    "    - no_replaced_tsv_file_path (str): The path to the output TSV file where no replacement occured.\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    output_directory = os.path.dirname(replaced_tsv_file_path)\n",
    "    if output_directory:\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "  # Open the TSV files for writing\n",
    "    with open(replaced_tsv_file_path, 'w', encoding='utf-8') as replaced_tsv_file, \\\n",
    "         open(no_replaced_tsv_file_path, 'w', encoding='utf-8') as no_replaced_tsv_file:\n",
    "\n",
    "        # Iterate over all files in the given directory\n",
    "        for filename in os.listdir(json_files_path):\n",
    "            if filename.endswith(\".json\"):\n",
    "                json_file_path = os.path.join(json_files_path, filename)\n",
    "                \n",
    "                # Read the JSON file\n",
    "                with open(json_file_path, 'r', encoding='utf-8') as file:\n",
    "                    data = json.load(file)\n",
    "                \n",
    "                # Concatenate all passage no replacement texts into one string\n",
    "                text_content_no_replaced =  \"\".join([passage[\"text\"] for passage in data[\"passages\"]])\n",
    "\n",
    "                # Apply Replacement \n",
    "                corrected_passages = correct_replacements(data[\"passages\"])\n",
    "\n",
    "                # Concatenate all passage replaced texts into one string\n",
    "                text_content_replaced = \"\".join([passage[\"text\"] for passage in corrected_passages])\n",
    "\n",
    "\n",
    "                # Extract PMC ID from the filename (assuming PMC ID is the filename without extension)\n",
    "                pmc_id = os.path.splitext(filename)[0]\n",
    "                \n",
    "                # Write the PMC ID and text content to the TSV file\n",
    "                replaced_tsv_file.write(f\"{pmc_id}\\t{text_content_replaced}\\n\")\n",
    "                \n",
    "                # Write the PMC ID and text content to the TSV file\n",
    "                no_replaced_tsv_file.write(f\"{pmc_id}\\t{text_content_no_replaced}\\n\")\n",
    "\n",
    "\n",
    "        print(f\"Processed and saved all entries to: {replaced_tsv_file_path}\")\n",
    "        print(f\"Un Processed and saved all entries to: {no_replaced_tsv_file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved all entries to: mesh_replaced.tsv\n",
      "Un Processed and saved all entries to: no_replaced.tsv\n"
     ]
    }
   ],
   "source": [
    "json_files_path = 'json_files'\n",
    "replaced_tsv_file_path = 'mesh_replaced.tsv'\n",
    "no_replaced_tsv_file_path = 'no_replaced.tsv'\n",
    "process_jsons_to_tsv(json_files_path, replaced_tsv_file_path, no_replaced_tsv_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
